{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "357557f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Available Tables:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cached_news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sqlite_sequence</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name\n",
       "0      cached_news\n",
       "1  sqlite_sequence"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì∞ Cached News Summary (84 records):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>article_count</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business</td>\n",
       "      <td>2026-02-05</td>\n",
       "      <td>15</td>\n",
       "      <td>2026-02-05 14:30:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>2026-02-05</td>\n",
       "      <td>14</td>\n",
       "      <td>2026-02-05 14:30:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Health</td>\n",
       "      <td>2026-02-05</td>\n",
       "      <td>15</td>\n",
       "      <td>2026-02-05 14:30:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Politics</td>\n",
       "      <td>2026-02-05</td>\n",
       "      <td>15</td>\n",
       "      <td>2026-02-05 14:31:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sports</td>\n",
       "      <td>2026-02-05</td>\n",
       "      <td>15</td>\n",
       "      <td>2026-02-05 14:30:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>0</td>\n",
       "      <td>2026-02-05 14:38:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Health</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>0</td>\n",
       "      <td>2026-02-05 14:38:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Politics</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>0</td>\n",
       "      <td>2026-02-05 14:38:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Sports</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>0</td>\n",
       "      <td>2026-02-05 14:38:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Technology</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>0</td>\n",
       "      <td>2026-02-05 14:38:27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         category        date  article_count           created_at\n",
       "0        Business  2026-02-05             15  2026-02-05 14:30:37\n",
       "1   Entertainment  2026-02-05             14  2026-02-05 14:30:57\n",
       "2          Health  2026-02-05             15  2026-02-05 14:30:50\n",
       "3        Politics  2026-02-05             15  2026-02-05 14:31:04\n",
       "4          Sports  2026-02-05             15  2026-02-05 14:30:43\n",
       "..            ...         ...            ...                  ...\n",
       "79  Entertainment  2026-01-23              0  2026-02-05 14:38:52\n",
       "80         Health  2026-01-23              0  2026-02-05 14:38:46\n",
       "81       Politics  2026-01-23              0  2026-02-05 14:38:58\n",
       "82         Sports  2026-01-23              0  2026-02-05 14:38:40\n",
       "83     Technology  2026-01-23              0  2026-02-05 14:38:27\n",
       "\n",
       "[84 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíª Technology News:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Technology</td>\n",
       "      <td>2026-02-05</td>\n",
       "      <td>[{\"title\": \"China Merchants Securities Reaffir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Technology</td>\n",
       "      <td>2026-02-04</td>\n",
       "      <td>[{\"title\": \"Pinterest Reportedly Fires Employe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Technology</td>\n",
       "      <td>2026-02-03</td>\n",
       "      <td>[{\"title\": \"Palantir Touts $2 Billion in Reven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Technology</td>\n",
       "      <td>2026-02-02</td>\n",
       "      <td>[{\"title\": \"Amazon\\u2019s Ring Wants to Wash A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Technology</td>\n",
       "      <td>2026-02-01</td>\n",
       "      <td>[{\"title\": \"What If the Sensors on Your Car We...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Technology</td>\n",
       "      <td>2026-01-31</td>\n",
       "      <td>[{\"title\": \"Jeffrey Epstein Had a \\u2018Person...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Technology</td>\n",
       "      <td>2026-01-30</td>\n",
       "      <td>[{\"title\": \"Peloton lays off 11 percent of its...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Technology</td>\n",
       "      <td>2026-01-29</td>\n",
       "      <td>[{\"title\": \"Apple\\u2019s second biggest acquis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Technology</td>\n",
       "      <td>2026-01-28</td>\n",
       "      <td>[{\"title\": \"The crypto bill is falling apart i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Technology</td>\n",
       "      <td>2026-01-27</td>\n",
       "      <td>[{\"title\": \"Self-driving truck startup Waabi i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Technology</td>\n",
       "      <td>2026-01-26</td>\n",
       "      <td>[{\"title\": \"Deepfake \\u2018Nudify\\u2019 Techno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Technology</td>\n",
       "      <td>2026-01-25</td>\n",
       "      <td>[{\"title\": \"New, Smarter Siri Is Reportedly We...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Technology</td>\n",
       "      <td>2026-01-24</td>\n",
       "      <td>[{\"title\": \"New Filtration Technology Could Be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Technology</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      category        date                                           articles\n",
       "0   Technology  2026-02-05  [{\"title\": \"China Merchants Securities Reaffir...\n",
       "1   Technology  2026-02-04  [{\"title\": \"Pinterest Reportedly Fires Employe...\n",
       "2   Technology  2026-02-03  [{\"title\": \"Palantir Touts $2 Billion in Reven...\n",
       "3   Technology  2026-02-02  [{\"title\": \"Amazon\\u2019s Ring Wants to Wash A...\n",
       "4   Technology  2026-02-01  [{\"title\": \"What If the Sensors on Your Car We...\n",
       "5   Technology  2026-01-31  [{\"title\": \"Jeffrey Epstein Had a \\u2018Person...\n",
       "6   Technology  2026-01-30  [{\"title\": \"Peloton lays off 11 percent of its...\n",
       "7   Technology  2026-01-29  [{\"title\": \"Apple\\u2019s second biggest acquis...\n",
       "8   Technology  2026-01-28  [{\"title\": \"The crypto bill is falling apart i...\n",
       "9   Technology  2026-01-27  [{\"title\": \"Self-driving truck startup Waabi i...\n",
       "10  Technology  2026-01-26  [{\"title\": \"Deepfake \\u2018Nudify\\u2019 Techno...\n",
       "11  Technology  2026-01-25  [{\"title\": \"New, Smarter Siri Is Reportedly We...\n",
       "12  Technology  2026-01-24  [{\"title\": \"New Filtration Technology Could Be...\n",
       "13  Technology  2026-01-23                                                 []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÑ Articles for Technology on 2026-02-05:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>China Merchants Securities Reaffirms Their Buy...</td>\n",
       "      <td>Markets Insider</td>\n",
       "      <td>https://markets.businessinsider.com/news/stock...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asia shares falter as tech sell-off spooks inv...</td>\n",
       "      <td>The Canberra Times</td>\n",
       "      <td>https://www.canberratimes.com.au/story/9168688...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Explained - Why Nvidia, Broadcom shares rose a...</td>\n",
       "      <td>CNBC TV18</td>\n",
       "      <td>https://www.cnbctv18.com/market/nvidia-broadco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TSMC plans major upgrade of Japan chip plant i...</td>\n",
       "      <td>The Japan Times</td>\n",
       "      <td>https://www.japantimes.co.jp/business/2026/02/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Texas DPS plans to increase surveillance over ...</td>\n",
       "      <td>FOX 4 News</td>\n",
       "      <td>https://www.fox4news.com/news/ai-cameras-drone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MPS Invests $16.5 Million in Unbound Medicine ...</td>\n",
       "      <td>scanx.trade</td>\n",
       "      <td>https://scanx.trade/stock-market-news/orders-d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>South Korean shares fall after tech selloff on...</td>\n",
       "      <td>MarketScreener</td>\n",
       "      <td>https://www.marketscreener.com/news/south-kore...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kyle Samani leaves Multicoin in ‚Äòbittersweet m...</td>\n",
       "      <td>Cointelegraph</td>\n",
       "      <td>https://cointelegraph.com/news/multicoin-exec-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Energy and critical minerals in focus as Jaish...</td>\n",
       "      <td>The Indian Express</td>\n",
       "      <td>https://indianexpress.com/shorts/india/energy-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ChatGPT boss ridiculed for online 'tantrum' ov...</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>https://www.bbc.com/news/articles/ce3edyx74jko...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>UK's ¬£8bn research fund faces 'hard decisions'...</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>https://www.bbc.com/news/articles/c8e50x1r237o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>US launches plan to tackle China's critical mi...</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>https://www.bbc.com/news/articles/c5y41r5rzrno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Netflix and Warner Bros struggle to defend merger</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>https://www.bbc.com/news/articles/c5ydndkmvy2o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Pinterest sacks engineers for tracking staff j...</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>https://www.bbc.com/news/articles/cn0k670n0ydo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>X offices raided in France as UK opens fresh i...</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>https://www.bbc.com/news/articles/ce3ex92557jo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title              source  \\\n",
       "0   China Merchants Securities Reaffirms Their Buy...     Markets Insider   \n",
       "1   Asia shares falter as tech sell-off spooks inv...  The Canberra Times   \n",
       "2   Explained - Why Nvidia, Broadcom shares rose a...           CNBC TV18   \n",
       "3   TSMC plans major upgrade of Japan chip plant i...    The Japan Times    \n",
       "4   Texas DPS plans to increase surveillance over ...          FOX 4 News   \n",
       "5   MPS Invests $16.5 Million in Unbound Medicine ...         scanx.trade   \n",
       "6   South Korean shares fall after tech selloff on...      MarketScreener   \n",
       "7   Kyle Samani leaves Multicoin in ‚Äòbittersweet m...       Cointelegraph   \n",
       "8   Energy and critical minerals in focus as Jaish...  The Indian Express   \n",
       "9   ChatGPT boss ridiculed for online 'tantrum' ov...            BBC News   \n",
       "10  UK's ¬£8bn research fund faces 'hard decisions'...            BBC News   \n",
       "11  US launches plan to tackle China's critical mi...            BBC News   \n",
       "12  Netflix and Warner Bros struggle to defend merger            BBC News   \n",
       "13  Pinterest sacks engineers for tracking staff j...            BBC News   \n",
       "14  X offices raided in France as UK opens fresh i...            BBC News   \n",
       "\n",
       "                                                  url  \n",
       "0   https://markets.businessinsider.com/news/stock...  \n",
       "1   https://www.canberratimes.com.au/story/9168688...  \n",
       "2   https://www.cnbctv18.com/market/nvidia-broadco...  \n",
       "3   https://www.japantimes.co.jp/business/2026/02/...  \n",
       "4   https://www.fox4news.com/news/ai-cameras-drone...  \n",
       "5   https://scanx.trade/stock-market-news/orders-d...  \n",
       "6   https://www.marketscreener.com/news/south-kore...  \n",
       "7   https://cointelegraph.com/news/multicoin-exec-...  \n",
       "8   https://indianexpress.com/shorts/india/energy-...  \n",
       "9   https://www.bbc.com/news/articles/ce3edyx74jko...  \n",
       "10  https://www.bbc.com/news/articles/c8e50x1r237o...  \n",
       "11  https://www.bbc.com/news/articles/c5y41r5rzrno...  \n",
       "12  https://www.bbc.com/news/articles/c5ydndkmvy2o...  \n",
       "13  https://www.bbc.com/news/articles/cn0k670n0ydo...  \n",
       "14  https://www.bbc.com/news/articles/ce3ex92557jo...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Daily Statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>total_articles</th>\n",
       "      <th>categories_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2026-02-05</td>\n",
       "      <td>89</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2026-02-04</td>\n",
       "      <td>90</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2026-02-03</td>\n",
       "      <td>90</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2026-02-02</td>\n",
       "      <td>90</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2026-02-01</td>\n",
       "      <td>90</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2026-01-31</td>\n",
       "      <td>90</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2026-01-30</td>\n",
       "      <td>90</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2026-01-29</td>\n",
       "      <td>90</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2026-01-28</td>\n",
       "      <td>90</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2026-01-27</td>\n",
       "      <td>90</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2026-01-26</td>\n",
       "      <td>90</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2026-01-25</td>\n",
       "      <td>90</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2026-01-24</td>\n",
       "      <td>45</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  total_articles  categories_count\n",
       "0   2026-02-05              89                 6\n",
       "1   2026-02-04              90                 6\n",
       "2   2026-02-03              90                 6\n",
       "3   2026-02-02              90                 6\n",
       "4   2026-02-01              90                 6\n",
       "5   2026-01-31              90                 6\n",
       "6   2026-01-30              90                 6\n",
       "7   2026-01-29              90                 6\n",
       "8   2026-01-28              90                 6\n",
       "9   2026-01-27              90                 6\n",
       "10  2026-01-26              90                 6\n",
       "11  2026-01-25              90                 6\n",
       "12  2026-01-24              45                 6\n",
       "13  2026-01-23               0                 6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Category Breakdown:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>days_with_data</th>\n",
       "      <th>total_articles</th>\n",
       "      <th>avg_articles_per_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business</td>\n",
       "      <td>14</td>\n",
       "      <td>195</td>\n",
       "      <td>13.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sports</td>\n",
       "      <td>14</td>\n",
       "      <td>195</td>\n",
       "      <td>13.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Technology</td>\n",
       "      <td>14</td>\n",
       "      <td>195</td>\n",
       "      <td>13.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Health</td>\n",
       "      <td>14</td>\n",
       "      <td>180</td>\n",
       "      <td>12.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Politics</td>\n",
       "      <td>14</td>\n",
       "      <td>180</td>\n",
       "      <td>12.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>14</td>\n",
       "      <td>179</td>\n",
       "      <td>12.785714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category  days_with_data  total_articles  avg_articles_per_day\n",
       "0       Business              14             195             13.928571\n",
       "1         Sports              14             195             13.928571\n",
       "2     Technology              14             195             13.928571\n",
       "3         Health              14             180             12.857143\n",
       "4       Politics              14             180             12.857143\n",
       "5  Entertainment              14             179             12.785714"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Search results for 'AI' (289 articles):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Technology</td>\n",
       "      <td>2026-02-05</td>\n",
       "      <td>Explained - Why Nvidia, Broadcom shares rose a...</td>\n",
       "      <td>CNBC TV18</td>\n",
       "      <td>https://www.cnbctv18.com/market/nvidia-broadco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Technology</td>\n",
       "      <td>2026-02-05</td>\n",
       "      <td>TSMC plans major upgrade of Japan chip plant i...</td>\n",
       "      <td>The Japan Times</td>\n",
       "      <td>https://www.japantimes.co.jp/business/2026/02/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Technology</td>\n",
       "      <td>2026-02-05</td>\n",
       "      <td>Energy and critical minerals in focus as Jaish...</td>\n",
       "      <td>The Indian Express</td>\n",
       "      <td>https://indianexpress.com/shorts/india/energy-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Technology</td>\n",
       "      <td>2026-02-05</td>\n",
       "      <td>X offices raided in France as UK opens fresh i...</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>https://www.bbc.com/news/articles/ce3ex92557jo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business</td>\n",
       "      <td>2026-02-05</td>\n",
       "      <td>US households become increasingly strained in ...</td>\n",
       "      <td>Times of India</td>\n",
       "      <td>https://timesofindia.indiatimes.com/business/i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Business</td>\n",
       "      <td>2026-02-05</td>\n",
       "      <td>OpenAI is hiring hundreds of 'forward deployed...</td>\n",
       "      <td>MarketScreener</td>\n",
       "      <td>https://www.marketscreener.com/news/openai-is-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Business</td>\n",
       "      <td>2026-02-05</td>\n",
       "      <td>Numerology Number 9 Prediction Today, February...</td>\n",
       "      <td>India Today</td>\n",
       "      <td>https://www.indiatoday.in/horoscopes/numerolog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Business</td>\n",
       "      <td>2026-02-05</td>\n",
       "      <td>The 'striking  silence' that convinced police ...</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>https://www.bbc.com/news/articles/c5yv1d7g2ldo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Business</td>\n",
       "      <td>2026-02-05</td>\n",
       "      <td>Warning of long airport queues under new EU bo...</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>https://www.bbc.com/news/articles/cn0k699pxwzo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Business</td>\n",
       "      <td>2026-02-05</td>\n",
       "      <td>Why Target is under fire over Minnesota ICE raids</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>https://www.bbc.com/news/articles/c4g4y4gwjpeo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     category        date                                              title  \\\n",
       "0  Technology  2026-02-05  Explained - Why Nvidia, Broadcom shares rose a...   \n",
       "1  Technology  2026-02-05  TSMC plans major upgrade of Japan chip plant i...   \n",
       "2  Technology  2026-02-05  Energy and critical minerals in focus as Jaish...   \n",
       "3  Technology  2026-02-05  X offices raided in France as UK opens fresh i...   \n",
       "4    Business  2026-02-05  US households become increasingly strained in ...   \n",
       "5    Business  2026-02-05  OpenAI is hiring hundreds of 'forward deployed...   \n",
       "6    Business  2026-02-05  Numerology Number 9 Prediction Today, February...   \n",
       "7    Business  2026-02-05  The 'striking  silence' that convinced police ...   \n",
       "8    Business  2026-02-05  Warning of long airport queues under new EU bo...   \n",
       "9    Business  2026-02-05  Why Target is under fire over Minnesota ICE raids   \n",
       "\n",
       "               source                                                url  \n",
       "0           CNBC TV18  https://www.cnbctv18.com/market/nvidia-broadco...  \n",
       "1    The Japan Times   https://www.japantimes.co.jp/business/2026/02/...  \n",
       "2  The Indian Express  https://indianexpress.com/shorts/india/energy-...  \n",
       "3            BBC News  https://www.bbc.com/news/articles/ce3ex92557jo...  \n",
       "4      Times of India  https://timesofindia.indiatimes.com/business/i...  \n",
       "5      MarketScreener  https://www.marketscreener.com/news/openai-is-...  \n",
       "6         India Today  https://www.indiatoday.in/horoscopes/numerolog...  \n",
       "7            BBC News  https://www.bbc.com/news/articles/c5yv1d7g2ldo...  \n",
       "8            BBC News  https://www.bbc.com/news/articles/cn0k699pxwzo...  \n",
       "9            BBC News  https://www.bbc.com/news/articles/c4g4y4gwjpeo...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Database connection closed\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Import libraries\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Cell 2: Connect to database\n",
    "DB_PATH = \"news_brief_01.db\"\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "\n",
    "# Cell 3: View all tables\n",
    "tables_query = \"SELECT name FROM sqlite_master WHERE type='table'\"\n",
    "tables_df = pd.read_sql_query(tables_query, conn)\n",
    "print(\"üìä Available Tables:\")\n",
    "display(tables_df)\n",
    "\n",
    "# Cell 4: View cached_news table summary\n",
    "summary_query = \"\"\"\n",
    "    SELECT \n",
    "        category,\n",
    "        date,\n",
    "        json_array_length(articles) as article_count,\n",
    "        created_at\n",
    "    FROM cached_news\n",
    "    ORDER BY date DESC, category\n",
    "\"\"\"\n",
    "summary_df = pd.read_sql_query(summary_query, conn)\n",
    "print(f\"\\nüì∞ Cached News Summary ({len(summary_df)} records):\")\n",
    "display(summary_df)\n",
    "\n",
    "# Cell 5: View specific category data\n",
    "tech_news = pd.read_sql_query(\"\"\"\n",
    "    SELECT category, date, articles \n",
    "    FROM cached_news \n",
    "    WHERE category = 'Technology' \n",
    "    ORDER BY date DESC\n",
    "\"\"\", conn)\n",
    "print(\"\\nüíª Technology News:\")\n",
    "display(tech_news)\n",
    "\n",
    "# Cell 6: Extract and view actual articles from JSON\n",
    "def extract_articles(row):\n",
    "    \"\"\"Extract articles from JSON column\"\"\"\n",
    "    articles = json.loads(row['articles'])\n",
    "    return pd.DataFrame(articles)\n",
    "\n",
    "# Get latest tech news articles\n",
    "if len(tech_news) > 0:\n",
    "    latest_tech = tech_news.iloc[0]\n",
    "    articles_df = extract_articles(latest_tech)\n",
    "    print(f\"\\nüìÑ Articles for {latest_tech['category']} on {latest_tech['date']}:\")\n",
    "    display(articles_df[['title', 'source', 'url']])\n",
    "\n",
    "# Cell 7: Statistics and visualizations\n",
    "stats_query = \"\"\"\n",
    "    SELECT \n",
    "        date,\n",
    "        SUM(json_array_length(articles)) as total_articles,\n",
    "        COUNT(DISTINCT category) as categories_count\n",
    "    FROM cached_news\n",
    "    GROUP BY date\n",
    "    ORDER BY date DESC\n",
    "\"\"\"\n",
    "stats_df = pd.read_sql_query(stats_query, conn)\n",
    "print(\"\\nüìà Daily Statistics:\")\n",
    "display(stats_df)\n",
    "\n",
    "# Cell 8: Category-wise breakdown\n",
    "category_query = \"\"\"\n",
    "    SELECT \n",
    "        category,\n",
    "        COUNT(*) as days_with_data,\n",
    "        SUM(json_array_length(articles)) as total_articles,\n",
    "        AVG(json_array_length(articles)) as avg_articles_per_day\n",
    "    FROM cached_news\n",
    "    GROUP BY category\n",
    "    ORDER BY total_articles DESC\n",
    "\"\"\"\n",
    "category_df = pd.read_sql_query(category_query, conn)\n",
    "print(\"\\nüìÇ Category Breakdown:\")\n",
    "display(category_df)\n",
    "\n",
    "# Cell 9: Search for specific keywords\n",
    "def search_news(keyword, conn):\n",
    "    \"\"\"Search for news articles containing keyword\"\"\"\n",
    "    query = \"\"\"\n",
    "        SELECT category, date, articles \n",
    "        FROM cached_news \n",
    "        WHERE json_extract(articles, '$') LIKE ?\n",
    "    \"\"\"\n",
    "    results = pd.read_sql_query(query, conn, params=[f'%{keyword}%'])\n",
    "    \n",
    "    all_matching = []\n",
    "    for _, row in results.iterrows():\n",
    "        articles = json.loads(row['articles'])\n",
    "        for article in articles:\n",
    "            if keyword.lower() in article['title'].lower():\n",
    "                all_matching.append({\n",
    "                    'category': row['category'],\n",
    "                    'date': row['date'],\n",
    "                    'title': article['title'],\n",
    "                    'source': article['source'],\n",
    "                    'url': article['url']\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(all_matching)\n",
    "\n",
    "# Example search\n",
    "search_results = search_news(\"AI\", conn)\n",
    "print(f\"\\nüîç Search results for 'AI' ({len(search_results)} articles):\")\n",
    "display(search_results.head(10))\n",
    "\n",
    "# Cell 10: Close connection\n",
    "conn.close()\n",
    "print(\"\\n‚úÖ Database connection closed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e80cf121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Available Tables:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql '\n    SELECT \n        category,\n        date,\n        json_array_length(articles) as article_count,\n        created_at\n    FROM cached_news\n    ORDER BY date DESC, category\n': no such table: cached_news",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOperationalError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yoges\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\sql.py:2664\u001b[39m, in \u001b[36mSQLiteDatabase.execute\u001b[39m\u001b[34m(self, sql, params)\u001b[39m\n\u001b[32m   2663\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2664\u001b[39m     \u001b[43mcur\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2665\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cur\n",
      "\u001b[31mOperationalError\u001b[39m: no such table: cached_news",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mDatabaseError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Cell 4: View cached_news table summary\u001b[39;00m\n\u001b[32m     17\u001b[39m summary_query = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[33m    SELECT \u001b[39m\n\u001b[32m     19\u001b[39m \u001b[33m        category,\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     24\u001b[39m \u001b[33m    ORDER BY date DESC, category\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m summary_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_sql_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43msummary_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müì∞ Cached News Summary (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(summary_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m records):\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     28\u001b[39m display(summary_df)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yoges\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\sql.py:528\u001b[39m, in \u001b[36mread_sql_query\u001b[39m\u001b[34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype, dtype_backend)\u001b[39m\n\u001b[32m    525\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m dtype_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib.no_default\n\u001b[32m    527\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[32m--> \u001b[39m\u001b[32m528\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m        \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    530\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    536\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yoges\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\sql.py:2728\u001b[39m, in \u001b[36mSQLiteDatabase.read_query\u001b[39m\u001b[34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[39m\n\u001b[32m   2717\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_query\u001b[39m(\n\u001b[32m   2718\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   2719\u001b[39m     sql,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2726\u001b[39m     dtype_backend: DtypeBackend | Literal[\u001b[33m\"\u001b[39m\u001b[33mnumpy\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mnumpy\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2727\u001b[39m ) -> DataFrame | Iterator[DataFrame]:\n\u001b[32m-> \u001b[39m\u001b[32m2728\u001b[39m     cursor = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2729\u001b[39m     columns = [col_desc[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor.description]\n\u001b[32m   2731\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yoges\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\sql.py:2676\u001b[39m, in \u001b[36mSQLiteDatabase.execute\u001b[39m\u001b[34m(self, sql, params)\u001b[39m\n\u001b[32m   2673\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01minner_exc\u001b[39;00m\n\u001b[32m   2675\u001b[39m ex = DatabaseError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExecution failed on sql \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msql\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2676\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mDatabaseError\u001b[39m: Execution failed on sql '\n    SELECT \n        category,\n        date,\n        json_array_length(articles) as article_count,\n        created_at\n    FROM cached_news\n    ORDER BY date DESC, category\n': no such table: cached_news"
     ]
    }
   ],
   "source": [
    "# Cell 1: Import libraries\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Cell 2: Connect to database\n",
    "DB_PATH = \"news_brief.db\"\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "\n",
    "# Cell 3: View all tables\n",
    "tables_query = \"SELECT name FROM sqlite_master WHERE type='table'\"\n",
    "tables_df = pd.read_sql_query(tables_query, conn)\n",
    "print(\"üìä Available Tables:\")\n",
    "display(tables_df)\n",
    "\n",
    "# Cell 4: View cached_news table summary\n",
    "summary_query = \"\"\"\n",
    "    SELECT \n",
    "        category,\n",
    "        date,\n",
    "        json_array_length(articles) as article_count,\n",
    "        created_at\n",
    "    FROM cached_news\n",
    "    ORDER BY date DESC, category\n",
    "\"\"\"\n",
    "summary_df = pd.read_sql_query(summary_query, conn)\n",
    "print(f\"\\nüì∞ Cached News Summary ({len(summary_df)} records):\")\n",
    "display(summary_df)\n",
    "\n",
    "# Cell 5: View specific category data\n",
    "tech_news = pd.read_sql_query(\"\"\"\n",
    "    SELECT category, date, articles \n",
    "    FROM cached_news \n",
    "    WHERE category = 'Technology' \n",
    "    ORDER BY date DESC\n",
    "\"\"\", conn)\n",
    "print(\"\\nüíª Technology News:\")\n",
    "display(tech_news)\n",
    "\n",
    "# Cell 6: Extract and view actual articles from JSON\n",
    "def extract_articles(row):\n",
    "    \"\"\"Extract articles from JSON column\"\"\"\n",
    "    articles = json.loads(row['articles'])\n",
    "    return pd.DataFrame(articles)\n",
    "\n",
    "# Get latest tech news articles\n",
    "if len(tech_news) > 0:\n",
    "    latest_tech = tech_news.iloc[0]\n",
    "    articles_df = extract_articles(latest_tech)\n",
    "    print(f\"\\nüìÑ Articles for {latest_tech['category']} on {latest_tech['date']}:\")\n",
    "    display(articles_df[['title', 'source', 'url']])\n",
    "\n",
    "# Cell 7: Statistics and visualizations\n",
    "stats_query = \"\"\"\n",
    "    SELECT \n",
    "        date,\n",
    "        SUM(json_array_length(articles)) as total_articles,\n",
    "        COUNT(DISTINCT category) as categories_count\n",
    "    FROM cached_news\n",
    "    GROUP BY date\n",
    "    ORDER BY date DESC\n",
    "\"\"\"\n",
    "stats_df = pd.read_sql_query(stats_query, conn)\n",
    "print(\"\\nüìà Daily Statistics:\")\n",
    "display(stats_df)\n",
    "\n",
    "# Cell 8: Category-wise breakdown\n",
    "category_query = \"\"\"\n",
    "    SELECT \n",
    "        category,\n",
    "        COUNT(*) as days_with_data,\n",
    "        SUM(json_array_length(articles)) as total_articles,\n",
    "        AVG(json_array_length(articles)) as avg_articles_per_day\n",
    "    FROM cached_news\n",
    "    GROUP BY category\n",
    "    ORDER BY total_articles DESC\n",
    "\"\"\"\n",
    "category_df = pd.read_sql_query(category_query, conn)\n",
    "print(\"\\nüìÇ Category Breakdown:\")\n",
    "display(category_df)\n",
    "\n",
    "# Cell 9: Search for specific keywords\n",
    "def search_news(keyword, conn):\n",
    "    \"\"\"Search for news articles containing keyword\"\"\"\n",
    "    query = \"\"\"\n",
    "        SELECT category, date, articles \n",
    "        FROM cached_news \n",
    "        WHERE json_extract(articles, '$') LIKE ?\n",
    "    \"\"\"\n",
    "    results = pd.read_sql_query(query, conn, params=[f'%{keyword}%'])\n",
    "    \n",
    "    all_matching = []\n",
    "    for _, row in results.iterrows():\n",
    "        articles = json.loads(row['articles'])\n",
    "        for article in articles:\n",
    "            if keyword.lower() in article['title'].lower():\n",
    "                all_matching.append({\n",
    "                    'category': row['category'],\n",
    "                    'date': row['date'],\n",
    "                    'title': article['title'],\n",
    "                    'source': article['source'],\n",
    "                    'url': article['url']\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(all_matching)\n",
    "\n",
    "# Example search\n",
    "search_results = search_news(\"AI\", conn)\n",
    "print(f\"\\nüîç Search results for 'AI' ({len(search_results)} articles):\")\n",
    "display(search_results.head(10))\n",
    "\n",
    "# Cell 10: Close connection\n",
    "conn.close()\n",
    "print(\"\\n‚úÖ Database connection closed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d72a94a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
